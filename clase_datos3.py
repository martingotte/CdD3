# -*- coding: utf-8 -*-
"""clase_datos3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15fbg-y0F_CIJoMYKrBmniviwWznrPxLi
"""

# @title Texto de título predeterminado
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import statsmodels.api as sm
from scipy import stats
import random
from sklearn.metrics import auc
from statsmodels.stats.anova import anova_lm



class GeneradoraDeDatos:
  def __init__(self,N=1000):
    self.N=N

  def distribucion_datos_normal(self,media,desvio):
    grilla=np.linspace(media-3*desvio,media+3*desvio,self.N)
    self.datos_normal=self.pdf_norm(grilla,media,desvio)
    return self.datos_normal

  def generar_datos_normal(self,media,desvio):
    return np.random.normal(media,desvio,self.N)

  def distribucion_datos_uniforme(self,min,max):
    grilla=np.linspace(min,max,self.N)
    self.datos_uniforme=self.pdf_uniforme(grilla,min,max)
    return self.datos_uniforme

  def generar_datos_uniforme(self,min,max):
    return np.random.uniform(min,max,self.N)

  def pdf_uniforme(self,x,min,max):
    return stats.uniform.pdf(x,min,max)

  def cdf_uniforme(self,x,min,max):
    return stats.uniform.cdf(x,min,max)

  def ppf_uniforme(self,x,min,max):
    return stats.uniform.ppf(x,min,max)

  def generar_datos_BS(self):
    u = np.random.uniform(size=(self.N,))
    y = u.copy()
    ind = np.where(u > 0.5)[0]
    y[ind] = np.random.normal(0, 1, size=len(ind))
    for j in range(5):
        ind = np.where((u > j * 0.1) & (u <= (j+1) * 0.1))[0]
        y[ind] = np.random.normal(j/2 - 1, 1/10, size=len(ind))
    return y

  def distribucion_datos_BS(self,min,max):
    grilla=np.linspace(min,max,self.N)
    sumatoria=0
    for j in range(5):
      sumatoria+=stats.norm.pdf(grilla,(j/2)-1,1/10)
    self.datos_BS=(1/2)*stats.norm.pdf(grilla,0,1)+(1/10)*sumatoria
    return grilla,self.datos_BS

  def generar_datos_exponencial(self,b):
    return np.random.exponential(scale=b,size=self.N)




class Estimacion:
  def __init__(self, datos):
    self.datos=datos

  def media(self):
    self.media=np.mean(self.datos)
    return self.media

  def mediana(self):
    self.mediana=np.median(self.datos)
    return self.mediana

  def desvio_estandar(self):
    self.desvio=np.std(self.datos)
    return self.desvio

  def varianza(self):
    self.varianza=np.var(self.datos)
    return self.varianza

  def cuartiles(self):
    self.q1=np.percentile(self.datos,25)
    self.q2=np.percentile(self.datos,50)
    self.q3=np.percentile(self.datos,75)
    return [self.q1,self.q2,self.q3]

  def maximo(self):
    maximo=np.max(self.datos)
    return maximo

  def minimo(self):
    minimo=np.min(self.datos)
    return minimo

  def calcular_histograma(self,h):
    puntos=np.arange(np.min(self.datos),np.max(self.datos)+h,h)
    histograma=np.zeros(len(puntos)-1)
    for i in range(len(histograma)):
      for j in range(len(self.datos)):
        if self.datos[j]>=puntos[i] and self.datos[j]<puntos[i+1]:
          histograma[i]+=1
      histograma[i]=histograma[i]/len(self.datos)
      histograma[i]=histograma[i]/h
    return histograma,puntos

  def evalua_histograma(self,h,x):
    histograma,puntos=self.calcular_histograma(h)
    estim_hist=np.zeros(len(x))
    for i in range(len(x)):
      for j in range(len(puntos)-1):
        if x[i]>=puntos[j] and x[i]<puntos[j+1]:
          estim_hist[i]=histograma[j]
    return estim_hist

  def kernel_uniforme(self,x):
    if (x>=-1/2) and (x<=1/2):
      valor_kernel_uniforme=1
    else:
      valor_kernel_uniforme=0
    return valor_kernel_uniforme

  def kernel_gaussiano(self,x):
    valor_kernel_gaussiano=1/np.sqrt(2*np.pi)*np.exp(-x**2/2)
    return valor_kernel_gaussiano

  def kernel_cuadratico(self,x):
    if (x>=-1/2) and (x<=1/2):
      valor_kernel_cuadratico=(3/4)*(1-x**2)
    else:
      valor_kernel_cuadratico=0
    return valor_kernel_cuadratico

  def kernel_triangular(self,x):
    valor_kernel_triangular=(1+x)*(x>=0 and x<=1)+(1-x)*(x<0 and x>-1)
    return valor_kernel_triangular

  def densidad_nucleo(self,h,kernel,x):
    if kernel=="uniforme":
      density=np.zeros_like(x,dtype=float)
      for i in range(len(x)):
        for j in range(len(self.datos)):
          density[i]+=self.kernel_uniforme((self.datos[j]-x[i])/h)
      density=density/(len(self.datos)*h)
    elif kernel=="gaussiano":
      density=np.zeros_like(x,dtype=float)
      for i in range(len(x)):
        for j in range(len(self.datos)):
          density[i]+=self.kernel_gaussiano((self.datos[j]-x[i])/h)
      density=density/(len(self.datos)*h)
    elif kernel=="cuadratico":
      density=np.zeros_like(x,dtype=float)
      for i in range(len(x)):
        for j in range(len(self.datos)):
          density[i]+=self.kernel_cuadratico((self.datos[j]-x[i])/h)
      density=density/(len(self.datos)*h)
    elif kernel=="triangular":
      density=np.zeros_like(x,dtype=float)
      for i in range(len(x)):
        for j in range(len(self.datos)):
          density[i]+=self.kernel_triangular((self.datos[j]-x[i])/h)
      density=density/(len(self.datos)*h)
    return density

  def EMC_normal(self,datos_teoricos):
    grilla_h=np.linspace(0.01,5,100)
    grilla_x=np.linspace(-5,5,300)
    errores=[]
    for h in grilla_h:
      datos_hist=self.evalua_histograma(h,grilla_x)
      errores.append(np.sum((datos_hist-datos_teoricos)**2)/len(datos_teoricos))
    h_minimo=grilla_h[np.argmin(errores)]
    EMC=np.min(errores)
    return h_minimo,EMC

  def EMC_kernel(self,datos_teoricos,kernel):
    grilla_h=np.linspace(0.01,5,100)
    grilla_x=np.linspace(-5,5,100)
    errores=[]
    for h in grilla_h:
      datos_hist=self.densidad_nucleo(h,kernel,grilla_x)
      errores.append(np.sum((datos_hist-datos_teoricos)**2)/len(datos_teoricos))
    h_minimo=grilla_h[np.argmin(errores)]
    EMC=np.min(errores)
    return h_minimo,EMC

  def pdf_norm(self,media=0,desvio=1):
    return stats.norm.pdf(self.datos,media,desvio)

  def ppf_norm(self,media=0,desvio=1):
    return stats.norm.ppf(self.datos,media,desvio)

  def cdf_norm(self,media=0,desvio=1):
    return stats.norm.cdf(self.datos,media,desvio)

  def pdf_uniforme(self,min,max):
    return stats.uniform.pdf(self.datos,min,max)

  def cdf_uniforme(self,min,max):
    return stats.uniform.cdf(self.datos,min,max)

  def ppf_uniforme(self,min,max):
    return stats.uniform.ppf(self.datos,min,max)

  def miqqplot(self):
    n=len(self.datos)
    cuantiles_teoricos=self.ppf_norm(np.arange(1/(n+1),1,1/(n+1)))
    datos_ordenados=np.sort(self.datos)
    cuantiles_muestrales=((datos_ordenados-np.mean(datos_ordenados))/np.std(datos_ordenados))
    plt.scatter(cuantiles_teoricos, cuantiles_muestrales, color='blue', marker='o')
    plt.xlabel('Cuantiles teóricos')
    plt.ylabel('Cuantiles muestrales')
    plt.plot(cuantiles_teoricos,cuantiles_teoricos , linestyle='-', color='red')
    plt.show()

  def dummies(self,columna):
    dummies=pd.get_dummies(self.datos[columna],columns=[columna],drop_first=True).astype(int)
    return dummies




class Regresion():
  def __init__(self,x,y):
    self.x=x
    self.y=y

  def separar_datos(self,porcentaje=.8,semilla=10):
    n = self.y.shape[0]
    n_train=int(n*0.8)
    n_test=n-n_train
    random.seed(semilla)
    cuales = random.sample(range(n), n_train)
    self.y_test = self.y.drop(cuales)
    self.x_test = self.x.drop(cuales)
    self.y_train = self.y.iloc[cuales]
    self.x_train = self.x.iloc[cuales]




class RegresionLineal(Regresion):
  def __init__(self,x,y):
    super().__init__(x,y)
    self.modelo=sm.OLS(self.y,self.x)
    self.resultados=self.modelo.fit()

  def resultados(self):
    print(self.resultados.summary())

  def parametros(self):
    return self.resultados.params()

  def p_valores(self):
    return self.resultados.pvalues()

  def obtener_residuos(self):
    return self.resultados.resid

  def varianza_residuos(self):
    return self.resultados.mse_resid

  def desvio_estimado(self):
    return self.resultados.bse()

  def t_obs(self):
    return self.resultados.tvalues()

  def int_confianza_b(self):
    return self.resultados.conf_int()

  def r_squared(self):
    return self.resultados.rsquared()

  def r_squared_adj(self):
    return self.resultados.rsquared_adj()

  def prediccion(self,x_new):
    prediccion=self.resultados.predict(x_new)
    return prediccion

  def predicciones(self,x_new):
    prediccion=self.resultados.get_prediction(x_new)
    return prediccion





class RegresionLogistica(Regresion):
  def __init__(self,x,y):
    super().__init__(x,y)
    self.modelo=sm.Logit(self.y,self.x)
    self.ajuste=self.modelo.fit()

  def resultados(self):
    print(self.ajuste.summary())

  def parametros(self):
    return self.ajuste.params

  def p_valores(self):
    return self.ajuste.pvalues

  def obtener_residuos(self):
    return self.ajuste.resid_pearson

  def desvio_estimado(self):
    return self.ajuste.bse

  def t_obs(self):
    return self.ajuste.tvalues

  def int_confianza_b(self):
    return self.ajuste.conf_int()

  def prediccion(self,x_new):
    prediccion=self.ajuste.predict(x_new)
    return prediccion

  def predicciones(self,x_new):
    prediccion=self.ajuste.get_prediction(x_new)
    return prediccion.summary_frame()

  def test(self,porcentaje=.8,semilla=10,punto_corte=0.5):
    super().separar_datos(porcentaje,semilla)
    regresion_train=RegresionLogistica(self.x_train,self.y_train)
    parametros_train=regresion_train.parametros()
    pi_test=[]
    for i in range(len(self.x_test)):
      pred=regresion_train.prediccion(self.x_test.iloc[[i]])
      pi_test.append(pred.item())
    self.y_pred=[]
    for i in range(len(pi_test)):
      if pi_test[i]<punto_corte:
        self.y_pred.append(0)
      else:
        self.y_pred.append(1)
    self.y_pred=np.array(self.y_pred)
    self.error=np.mean(self.y_pred!=self.y_test.values)
    self.sensibilidad=(np.sum((self.y_pred==1)&(self.y_test==1)))/np.sum(self.y_test==1)
    self.especificidad=(np.sum((self.y_pred==0)&(self.y_test==0)))/np.sum(self.y_test==0)
    return self.error,self.sensibilidad,self.especificidad

  def indice_youden(self,porcentaje=.8,semilla=10):
    grilla_corte=np.linspace(0,1,100)
    lista_youden=[]
    self.lista_sensibilidad=[]
    self.lista_especificidad=[]
    for i in range(len(grilla_corte)):
      error,sensibilidad,especificidad=self.test(porcentaje,semilla,punto_corte=grilla_corte[i])
      lista_youden.append(sensibilidad+especificidad-1)
      self.lista_sensibilidad.append(sensibilidad)
      self.lista_especificidad.append(especificidad)
    indice_youden=np.argmax(lista_youden)
    return grilla_corte[indice_youden],self.lista_sensibilidad[indice_youden],self.lista_especificidad[indice_youden]

  def AUC(self):
    instancia=RegresionLogistica(self.x,self.y)
    _,_,_=instancia.indice_youden()
    sensibilidad=np.array(instancia.lista_sensibilidad)
    especificidad=np.array(instancia.lista_especificidad)
    return auc(1-especificidad,sensibilidad)



class anova():
  def __init__(self, resultados, resultados_reducidos):
    self.resultados = resultados
    self.resultados_reducidos = resultados_reducidos
    self.anova=anova_lm(self.resultados_reducidos,self.resultados)

  def resultados(self):
    print(self.anova)

  def p_valores(self):
    return self.anova.pvalues

  def f_valores(self):
    return self.anova.fvalue